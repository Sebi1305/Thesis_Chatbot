{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16151811",
   "metadata": {},
   "source": [
    "# Action Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3be9fe",
   "metadata": {},
   "source": [
    "Hier wird eine neue Funktion implementiert, die den ermittelten Intent und die extrahierten Informationen aus dem Slot Filling als Input nimmt und SQL Queries generiert, um die gesuchte Info aus der Datenbank zu holen. Die Informationen aus der Datenbank gibt die Funktion als Output an die Response Generation weiter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fd30c",
   "metadata": {},
   "source": [
    "## Import benötigter Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41749ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:27.874462Z",
     "start_time": "2022-02-25T12:10:18.220789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebi\\anaconda3\\envs\\prototype\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "Scipy not supported!\n"
     ]
    }
   ],
   "source": [
    "# import of necessary libraries\n",
    "import nltk \n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "import datefinder\n",
    "import numpy\n",
    "import tflearn \n",
    "import tensorflow\n",
    "import random \n",
    "import json\n",
    "import pickle\n",
    "import spacy\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "import sqlite3\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bac6de",
   "metadata": {},
   "source": [
    "## Vorbereitungen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8a684",
   "metadata": {},
   "source": [
    "#### intent classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18556fd2",
   "metadata": {},
   "source": [
    "Das Neuronale Netzwerk wurde zuvor in einem separaten Notebook erstellt, trainert und gespeichert. Der folgende Code versucht das gespeciherte Neuronale Netzwerk zu laden. Falls dies nicht möglich sein sollte wird ein neues Neuronales Netzwerk erstellt und trainiert. Hierzu werden die Trainingsdaten \"data.pickle\" geladen und die Layer des Netztes definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba1d458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:27.889143Z",
     "start_time": "2022-02-25T12:10:27.874462Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\"\n",
    "with open(path + \"\\data.pickle\", \"rb\") as f:\n",
    "    words, labels, training, output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf2b8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.430490Z",
     "start_time": "2022-02-25T12:10:27.892097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebi\\anaconda3\\envs\\prototype\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "tensorflow.compat.v1.reset_default_graph()\n",
    "    \n",
    "# Creating the Neural Network\n",
    "net = tflearn.input_data(shape= [None, len(training[0])]) #input layer Neurons = numer of words in training\n",
    "net = tflearn.fully_connected(net, 8) #hidden layer fully connected with 8 neuron\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\" ) #output layer 6 Neurons = labels\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\")\n",
    "except:\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611c102e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.462061Z",
     "start_time": "2022-02-25T12:10:28.433055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tflearn.models.dnn.DNN at 0x20d792b65c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec67aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.477963Z",
     "start_time": "2022-02-25T12:10:28.465000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformation des Inputs in Zahlen, um es lesbar für das Neuronale Netz zu machen\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    \n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    \n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    \n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f3588",
   "metadata": {},
   "source": [
    "#### slot filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5cb81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:48:04.044028Z",
     "start_time": "2022-02-20T14:48:04.027074Z"
    }
   },
   "source": [
    "Für die Extraktion der verschiedenen Zusatzinformationen müssen unteranderem bereits bekannte Namen aus der Datenbank extrahiert werden und in Listen gespeichert werden. Eine Funktion gleicht den Input des Benutzers mit den Namen ab, um zu prüfen ob der vom Benutzer genannte Professor bekannt ist oder nicht. Zusätzlich werden zuvor trainerte Custom NER Modelle geladen und die Slot Filling definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099c0392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.492923Z",
     "start_time": "2022-02-25T12:10:28.480956Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"PROF_INFO_DB.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select first_name FROM PROF_INFO_TABLE\")\n",
    "conn.commit()\n",
    "first_names = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "#first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d774eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.508754Z",
     "start_time": "2022-02-25T12:10:28.495602Z"
    }
   },
   "outputs": [],
   "source": [
    "#liste mit allen first_names\n",
    "first_names_list = []\n",
    "for i in range(len(first_names)):\n",
    "    answer = \" \".join(first_names[i])\n",
    "    answer.strip()\n",
    "    first_names_list.append(answer)\n",
    "\n",
    "#first_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50161ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.523592Z",
     "start_time": "2022-02-25T12:10:28.512690Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"PROF_INFO_DB.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select last_name FROM PROF_INFO_TABLE\")\n",
    "conn.commit()\n",
    "last_names = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "#last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b5ec84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:28.539553Z",
     "start_time": "2022-02-25T12:10:28.525586Z"
    }
   },
   "outputs": [],
   "source": [
    "#liste mit allen last_names\n",
    "last_names_list = []\n",
    "for i in range(len(last_names)):\n",
    "    answer = \" \".join(last_names[i])\n",
    "    answer.strip()\n",
    "    last_names_list.append(answer)\n",
    "\n",
    "#last_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f548b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:49.718489Z",
     "start_time": "2022-02-25T12:10:28.541543Z"
    }
   },
   "outputs": [],
   "source": [
    "#lod the custom NER models\n",
    "nlp_research_area = spacy.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\3. Slot Filling/custom_ner_model_research_area\")\n",
    "nlp_study = spacy.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\3. Slot Filling/custom_ner_model_study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58329dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:22:42.298907Z",
     "start_time": "2022-02-25T12:22:42.278996Z"
    }
   },
   "outputs": [],
   "source": [
    "def slot_filling(inp, intent):\n",
    "    # liste with intents that need information\n",
    "    intent_prof_contact=[\"prof_telephone_query_name\", \"prof_email_query_name\", \"prof_office_query_name\", \"prof_research_area_query_name\", \"prof_study_query_name\"]\n",
    "    intent_generic_conversation=[\"greeting\",\"greeting_response\",\"courtesy_greeting\",\"courtesy_greeting_response\",\"real_name_query\", \"goodbye\",\"task_response\"]\n",
    "        \n",
    "    if intent == \"prof_name_query_telephone\":\n",
    "        re_number_1 = r\"\\D[\\d]{2}? [\\d]{4} [\\d]{3} [\\d]{4}\"\n",
    "        re_number_2 = r\"\\D[\\d]{2}? [\\d]{4} [\\d]{3} [\\d]{3}\"\n",
    "        re_number_3 = r\"\\D[\\d]{2} [\\(][\\d]{1}[\\)] [\\d]{4} [\\d]{3} [\\d]{4}\"\n",
    "        extracted_info = re.compile(\"(%s|%s|%s)\" % (re_number_1, re_number_2, re_number_3)).findall(inp)\n",
    "\n",
    "        \n",
    "        \n",
    "    elif intent == \"prof_name_query_email\":\n",
    "        extracted_info = re.findall('\\S+@\\S+', inp)\n",
    "        \n",
    "    elif intent == \"prof_name_query_office\":\n",
    "        re_office_1 = r\"[A-Z, a-z].\\d{1}.\\d{2}\"\n",
    "        re_office_2 = r\"[A-Z, a-z].\\d{3}\"\n",
    "        extracted_info = re.compile(\"(%s|%s)\" % (re_office_1, re_office_2)).findall(inp)\n",
    "        \n",
    "    elif intent == \"prof_name_query_research_area\":\n",
    "        doc = nlp_research_area(inp)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"RESEARCH_AREA\":\n",
    "                extracted_info = ent.text    \n",
    "    \n",
    "    elif intent == \"prof_name_query_study\":\n",
    "        doc = nlp_study(inp)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"STUDY\":\n",
    "                extracted_info = ent.text  \n",
    "                \n",
    "    elif intent == \"prof_name_query_lastname\":\n",
    "        print(\"pog\")\n",
    "        for first_name in first_names_list:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, first_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = first_name\n",
    "    \n",
    "    elif intent == \"prof_name_query_firstname\":\n",
    "        for last_name in last_names_list:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, last_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = last_name\n",
    "        \n",
    "    elif intent in intent_prof_contact:\n",
    "        for last_name in last_names_list:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, last_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = last_name\n",
    "                    \n",
    "    elif intent in intent_generic_conversation:\n",
    "        extracted_info = \"generic intent no need for info extraction\"\n",
    "    \n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60938a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T16:46:42.650308Z",
     "start_time": "2022-02-24T16:46:42.642329Z"
    }
   },
   "source": [
    "## Action Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3217bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:31:49.811821Z",
     "start_time": "2022-02-25T12:31:49.793868Z"
    }
   },
   "outputs": [],
   "source": [
    "def action_execution_retrieval(intent, condition = str):\n",
    "    # liste with intents that need information\n",
    "    intent_generic_conversation=[\"greeting\",\"greeting_response\",\"courtesy_greeting\",\"courtesy_greeting_response\",\"real_name_query\", \"goodbye\",\"task_response\"]\n",
    "\n",
    "    \n",
    "    #connect to database\n",
    "    conn = sqlite3.connect(\"PROF_INFO_DB.db\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    #TELEPHONE\n",
    "    if intent == \"prof_name_query_telephone\":\n",
    "        cur.execute(\"select title, first_name, last_name FROM PROF_INFO_TABLE where telephone = ? COLLATE NOCASE\", (condition[0],))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "\n",
    "    elif intent == \"prof_name_query_email\": \n",
    "        cur.execute(\"select title, first_name, last_name FROM PROF_INFO_TABLE where email = ? COLLATE NOCASE\", (condition[0],))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_name_query_office\":\n",
    "        cur.execute(\"select title, first_name, last_name FROM PROF_INFO_TABLE where office = ? COLLATE NOCASE\", (condition[0],))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_name_query_research_area\":\n",
    "        #print(\"pog\", condition[0])\n",
    "        cur.execute(\"SELECT title, first_name, last_name FROM PROF_INFO_TABLE INNER JOIN PROF_RESEARCH_AREA_TABLE on PROF_RESEARCH_AREA_TABLE.prof_id = PROF_INFO_TABLE.prof_id WHERE research_area = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchone()\n",
    "    \n",
    "    elif intent == \"prof_name_query_study\":\n",
    "        #print(\"pog\", condition[0])\n",
    "        cur.execute(\"SELECT title, first_name, last_name FROM PROF_INFO_TABLE INNER JOIN PROF_STUDY_TABLE on PROF_STUDY_TABLE.prof_id = PROF_INFO_TABLE.prof_id WHERE study = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchone()\n",
    "        \n",
    "    elif intent == \"prof_name_query_lastname\":\n",
    "        cur.execute(\"select last_name FROM PROF_INFO_TABLE where first_name = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_name_query_firstname\":\n",
    "        cur.execute(\"select first_name FROM PROF_INFO_TABLE where last_name = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_telephone_query_name\":\n",
    "        cur.execute(\"select telephone FROM PROF_INFO_TABLE where last_name =? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "    \n",
    "    elif intent == \"prof_email_query_name\":\n",
    "        cur.execute(\"select email FROM PROF_INFO_TABLE where last_name =? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_office_query_name\":\n",
    "        cur.execute(\"select office FROM PROF_INFO_TABLE where last_name =? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_research_area_query_name\":\n",
    "        cur.execute(\"SELECT research_area FROM PROF_RESEARCH_AREA_TABLE INNER JOIN PROF_INFO_TABLE on PROF_INFO_TABLE.prof_id = PROF_RESEARCH_AREA_TABLE.prof_id WHERE last_name = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    elif intent == \"prof_study_query_name\":\n",
    "        cur.execute(\"SELECT study FROM PROF_STUDY_TABLE INNER JOIN PROF_INFO_TABLE on PROF_INFO_TABLE.prof_id = PROF_STUDY_TABLE.prof_id WHERE last_name = ? COLLATE NOCASE\", (condition,))\n",
    "        conn.commit()\n",
    "        answer = cur.fetchall()\n",
    "        \n",
    "    \n",
    "    if intent in intent_generic_conversation:\n",
    "        answer = \"generic conversation no data retrieval necessary\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388655b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a497d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c0ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fe669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5dbde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e6ec70",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d47ca86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:10:49.774265Z",
     "start_time": "2022-02-25T12:10:49.761298Z"
    }
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    log = []\n",
    "    print(\"Start talking with me!(type quit to stop):\")\n",
    "    while True:\n",
    "        inp = input(\"You: \")\n",
    "        log.append(inp) #saves all input of user in list\n",
    "        if inp.lower() == \"quit\":\n",
    "            print(\"Goodbye :)\")\n",
    "            break\n",
    "        \n",
    "        # predict the intent\n",
    "        results = model.predict([bag_of_words(inp, words)])[0] #output is just a probability for each label\n",
    "        results_index = numpy.argmax(results) #index of greatest value\n",
    "        intent = labels[results_index] #output is the most probable label\n",
    "        print(intent)\n",
    "        extracted_info = slot_filling(inp, intent)\n",
    "                \n",
    "        answer = action_execution_retrieval(intent, extracted_info)\n",
    "        \n",
    "        \n",
    "        print(\"condition-->\", extracted_info)\n",
    "        print(\"answer from db-->\", answer)\n",
    "        \n",
    "\n",
    "\n",
    "    return log # returns list of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e50fc9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T12:32:10.230960Z",
     "start_time": "2022-02-25T12:31:53.833409Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with me!(type quit to stop):\n",
      "You: what is the number of frau salmen \n",
      "prof_telephone_query_name\n",
      "condition--> Salmen\n",
      "answer from db--> [('+49 7131 504 477',)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e57ee30c65ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-89c331106386>\u001b[0m in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Start talking with me!(type quit to stop):\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#saves all input of user in list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"quit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prototype\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prototype\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d02a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677d2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba27a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbf9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de5d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "prototype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
