{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16151811",
   "metadata": {},
   "source": [
    "# Chatbot Prototyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3be9fe",
   "metadata": {},
   "source": [
    "In diesem Notebook werden alle Komponenten, die in den anderen Notebooks entwickelt, trainert und gespeichert wurden, zusammengefügt, um einen voll funktionsfähigen Chatbot zu bilden. \n",
    "\n",
    "Im folgenden sind einige kleinere Vorbereitungen zu erledigen, wie das laden der Modells und die Extraktion einiger Informationen aus der Datenbank um die Funktionsfähigkeit des Chatbots zu gewährleisten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fd30c",
   "metadata": {},
   "source": [
    "## Import benötigter Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41749ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:09.769094Z",
     "start_time": "2022-02-20T14:34:57.257855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebi\\anaconda3\\envs\\prototype\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "Scipy not supported!\n"
     ]
    }
   ],
   "source": [
    "# import of necessary libraries\n",
    "import nltk \n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "import datefinder\n",
    "import numpy\n",
    "import tflearn \n",
    "import tensorflow\n",
    "import random \n",
    "import json\n",
    "import pickle\n",
    "import spacy\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "import sqlite3\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bac6de",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vorbereitungen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8a684",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### intent classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18556fd2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Das Neuronale Netzwerk wurde zuvor in einem separaten Notebook erstellt, trainert und gespeichert. Der folgende Code versucht das gespeciherte Neuronale Netzwerk zu laden. Falls dies nicht möglich sein sollte wird ein neues Neuronales Netzwerk erstellt und trainiert. Hierzu werden die Trainingsdaten \"data.pickle\" geladen und die Layer des Netztes definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba1d458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:09.784328Z",
     "start_time": "2022-02-20T14:35:09.771361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\"\n",
    "with open(path + \"\\data.pickle\", \"rb\") as f:\n",
    "    words, labels, training, output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf2b8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.430028Z",
     "start_time": "2022-02-20T14:35:09.787319Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebi\\anaconda3\\envs\\prototype\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "tensorflow.compat.v1.reset_default_graph()\n",
    "    \n",
    "# Creating the Neural Network\n",
    "net = tflearn.input_data(shape= [None, len(training[0])]) #input layer Neurons = numer of words in training\n",
    "net = tflearn.fully_connected(net, 8) #hidden layer fully connected with 8 neuron\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\" ) #output layer 6 Neurons = labels\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\")\n",
    "except:\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\2. Intent Classififcation\\model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611c102e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.461662Z",
     "start_time": "2022-02-20T14:35:10.430028Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tflearn.models.dnn.DNN at 0x1090bcb0a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec67aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.477528Z",
     "start_time": "2022-02-20T14:35:10.464268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Transformation des Inputs in Zahlen, um es lesbar für das Neuronale Netz zu machen\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    \n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    \n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    \n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f3588",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### slot filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5cb81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:48:04.044028Z",
     "start_time": "2022-02-20T14:48:04.027074Z"
    },
    "hidden": true
   },
   "source": [
    "Für die Extraktion der verschiedenen Zusatzinformationen müssen unteranderem bereits bekannte Namen aus der Datenbank extrahiert werden und in Listen gespeichert werden. Eine Funktion gleicht den Input des Benutzers mit den Namen ab, um zu prüfen ob der vom Benutzer genannte Professor bekannt ist oder nicht. Zusätzlich werden zuvor trainerte Custom NER Modelle geladen und die Slot Filling definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099c0392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.492615Z",
     "start_time": "2022-02-20T14:35:10.480227Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"PROF_INFO_DB.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select first_name FROM PROF_INFO_TABLE\")\n",
    "conn.commit()\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "#rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d774eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.508699Z",
     "start_time": "2022-02-20T14:35:10.495025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#liste mit allen first_names\n",
    "first_names = []\n",
    "for i in range(len(rows)):\n",
    "    answer = \" \".join(rows[i])\n",
    "    answer.strip()\n",
    "    first_names.append(answer)\n",
    "\n",
    "#first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50161ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.524362Z",
     "start_time": "2022-02-20T14:35:10.511638Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"PROF_INFO_DB.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select last_name FROM PROF_INFO_TABLE\")\n",
    "conn.commit()\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "#rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b5ec84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:10.539342Z",
     "start_time": "2022-02-20T14:35:10.526834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#liste mit allen last_names\n",
    "last_names = []\n",
    "for i in range(len(rows)):\n",
    "    answer = \" \".join(rows[i])\n",
    "    answer.strip()\n",
    "    last_names.append(answer)\n",
    "\n",
    "#last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f548b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:30.340612Z",
     "start_time": "2022-02-20T14:35:10.541984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lod the custom NER models\n",
    "nlp_research_area = spacy.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\3. Slot Filling/custom_ner_model_research_area\")\n",
    "nlp_study = spacy.load(r\"C:\\Users\\Sebi\\OneDrive\\Studium\\Thesis_Chatbot\\3. Slot Filling/custom_ner_model_study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58329dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:38:56.606960Z",
     "start_time": "2022-02-20T14:38:56.583020Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def slot_filling(inp, intent):\n",
    "    # liste with intents that need information\n",
    "    intent_telephone = [\"prof_name_query_telephone\",\"extract_new_telephone\" ]\n",
    "    intent_email=[\"prof_name_query_email\",\"extract_new_email\" ]\n",
    "    intent_office=[\"prof_name_query_office\", \"extract_new_office\"]\n",
    "    intent_research_area=[\"prof_name_query_research_area\", \"extract_new_research_area\"]\n",
    "    intent_study=[\"prof_name_query_study\", \"extract_new_study\"]\n",
    "    intent_last_name=[\"prof_name_query_lastname\"]\n",
    "    intent_first_name=[\"prof_name_query_firstname\"]\n",
    "    intent_prof_contact=[\"prof_telephone_query_name\", \"prof_email_query_name\", \"prof_office_query_name\", \"prof_research_area_query_name\", \"prof_study_query_name\"]\n",
    "    intent_generic_conversation=[\"greeting\",\"greeting_response\",\"courtesy_greeting\",\"courtesy_greeting_response\",\"real_name_query\", \"goodbye\",\"task_response\"]\n",
    "    #get the phone number\n",
    "    if intent in intent_telephone:\n",
    "        re_number_1 = r\"[\\d]{2}? [\\d]{4} [\\d]{3} [\\d]{4}\"\n",
    "        re_number_2 = r\"[\\d]{2} [\\(][\\d]{1}[\\)] [\\d]{4} [\\d]{3} [\\d]{4}\"\n",
    "        extracted_info = re.compile(\"(%s|%s)\" % (re_number_1, re_number_2)).findall(inp)\n",
    "        \n",
    "    elif intent in intent_email:\n",
    "        extracted_info = re.findall('\\S+@\\S+', inp)\n",
    "        \n",
    "    elif intent in intent_office:\n",
    "        extracted_info = re.findall('[A-Z].\\d{1}.\\d{2}', inp)\n",
    "        \n",
    "    elif intent in intent_research_area:\n",
    "        doc = nlp_research_area(inp)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"RESEARCH_AREA\":\n",
    "                extracted_info = ent.text    \n",
    "    \n",
    "    elif intent in intent_research_area:\n",
    "        doc = nlp_study(inp)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"STUDY\":\n",
    "                extracted_info = ent.text  \n",
    "                \n",
    "    elif intent in intent_last_name:\n",
    "        for last_name in last_names:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, last_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = last_name\n",
    "    \n",
    "    elif intent in intent_first_name:\n",
    "        for first_name in first_names:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, first_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = first_name\n",
    "        \n",
    "    elif intent in intent_prof_contact:\n",
    "        for last_name in last_names:\n",
    "            for word in inp.split():\n",
    "                if SequenceMatcher(None, last_name, word).ratio() >= 0.7:\n",
    "                    extracted_info = last_name\n",
    "                    \n",
    "    elif intent in intent_generic_response:\n",
    "        extracted_info = \"generic intent no need for info extraction\"\n",
    "    \n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6ec70",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d47ca86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:35:30.382627Z",
     "start_time": "2022-02-20T14:35:30.374724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    log = []\n",
    "    print(\"Start talking with me!(type quit to stop):\")\n",
    "    while True:\n",
    "        inp = input(\"You: \")\n",
    "        log.append(inp) #saves all input of user in list\n",
    "        if inp.lower() == \"quit\":\n",
    "            print(\"Goodbye :)\")\n",
    "            break\n",
    "        \n",
    "        # predict the intent\n",
    "        results = model.predict([bag_of_words(inp, words)])[0] #output is just a probability for each label\n",
    "        results_index = numpy.argmax(results) #index of greatest value\n",
    "        intent = labels[results_index] #output is the most probable label\n",
    "        print(intent)\n",
    "        extracted_info = slot_filling(inp, intent)\n",
    "        \n",
    "        print(extracted_info)\n",
    "        \n",
    "\n",
    "\n",
    "    return log # returns list of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e50fc9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T14:36:57.913038Z",
     "start_time": "2022-02-20T14:35:30.382627Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with me!(type quit to stop):\n",
      "You: Hello\n",
      "greeting\n",
      "test\n",
      "You: How are you?\n",
      "courtesy_greeting\n",
      "test\n",
      "You: What is the email of mr. lanquillon\n",
      "prof_email_query_name\n",
      "Lanquillon\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e57ee30c65ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-cdf1e49c1e66>\u001b[0m in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Start talking with me!(type quit to stop):\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#saves all input of user in list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"quit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prototype\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prototype\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea751ee4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69661ebc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d02a80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677d2f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba27a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbf9dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de5d31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "prototype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
